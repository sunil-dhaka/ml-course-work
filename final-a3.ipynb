{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Q1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part(a)\n",
    "#### Code up the perceptron algorithm described on slide 7 of Lecture 15 using the same notation as in the slides.  [10 points]\n",
    "\n",
    "- define the function that will be used in next sextions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "# to reproduce results\n",
    "np.random.seed(1)\n",
    "'''\n",
    "possible to give x,y in one 2D array then some indexing changes needs to be done\n",
    "input: hyper-parameters and data wit labels\n",
    "output: perceptron learned weight vector\n",
    "'''\n",
    "def percep(feature_data,labels,margin=0,learn_rate=1,n_iter=100):\n",
    "    # convert class labels into +1/-1\n",
    "    # 0 --> -1\n",
    "    # 1 --> +1\n",
    "\n",
    "    class_label=[]\n",
    "    for c in labels:\n",
    "        if c==0:\n",
    "            class_label.append(-1)\n",
    "        else:\n",
    "            class_label.append(1)\n",
    "    # print(class_label)\n",
    "    # get feature length and total no of samples\n",
    "    N,d=feature_data.shape\n",
    "\n",
    "    # intialize w\n",
    "    # with w=zeros it get stuck in the for loop\n",
    "    w=np.ones(d)\n",
    "    t=0\n",
    "    # for loop\n",
    "    for i in range(n_iter):\n",
    "        '''\n",
    "        break while loop when mistake condition satisfies in if statement\n",
    "        '''\n",
    "        while(True):\n",
    "            # If `high` is None (the default), then results are from [0, `low`).\n",
    "            rand=np.random.randint(N)\n",
    "            curr_x=feature_data[rand]\n",
    "            curr_y=class_label[rand]\n",
    "\n",
    "            # mistake condition\n",
    "            if (curr_y*np.dot(w.T,curr_x)<margin): # margin =0(default)\n",
    "                w=w+curr_x*curr_y*learn_rate # learn_rate=1(default)\n",
    "                # print(f'mistake -- {w}')\n",
    "                break\n",
    "\n",
    "    return w"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part(b)\n",
    "\n",
    "#### Write functions to make predictions using the algorithm for the banknotes dataset. Preprocess the dataset to handle missing and anomalous data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### read data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "# easy way to get txt into csv using pandas read_table\n",
    "cols=['variance','skewness','curtosis','entropy-of-image','class']\n",
    "data=pd.read_table('datasets/data_banknote_authentication.txt',sep=',',names=cols)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### pre-process check"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- points with variance less than zero ignored can be ignored"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "variance            0\n",
       "skewness            0\n",
       "curtosis            0\n",
       "entropy-of-image    0\n",
       "class               0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.isnull().sum()\n",
    "# no missing data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- no missing data in banknote dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### predict and f1-score func"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "takes a new-test point and\n",
    "returns its class using\n",
    "# 0 --> -1\n",
    "# 1 --> +1\n",
    "'''\n",
    "def predict(x,w):\n",
    "    pred=np.dot(w.T,x)\n",
    "    if pred > 0:\n",
    "        return 1\n",
    "    else:\n",
    "        return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "inputs: true and predicted labels; both inputs are lists\n",
    "output: return f1-score\n",
    "All formulas are used from slides\n",
    "'''\n",
    "def f1_score(y_true,y_pred):\n",
    "    # initiate variables\n",
    "    tp=0\n",
    "    fp=0\n",
    "    fn=0\n",
    "\n",
    "    for i in range(len(y_pred)):\n",
    "        # true positives cond\n",
    "        if y_pred[i]==y_true[i] and y_true[i]==1:\n",
    "            tp+=1\n",
    "        # false negatives cond\n",
    "        elif y_true[i]==1 and y_pred[i]==0:\n",
    "            fn+=1\n",
    "        # false positives cond\n",
    "        elif y_true[i]==0 and y_pred[i]==1:\n",
    "            fp+=1\n",
    "\n",
    "    # calculate stats\n",
    "    p=tp/(tp+fp)\n",
    "    r=tp/(tp+fn)\n",
    "\n",
    "    # calc f1-score from stats(p & r)\n",
    "    f1=(2*p*r)/(p+r)\n",
    "\n",
    "    return round(f1,3) # round up-to only 3 decimal points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred=[predict(p,w) for p in f]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 Score is >> 0.906\n"
     ]
    }
   ],
   "source": [
    "print(f'F1 Score is >> {f1_score(y,y_pred)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part(c)\n",
    "\n",
    "#### Train the algorithm on the dataset using cross-validation and report cross-validated test set error "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "input: total observed points, no of folds, random state\n",
    "output: shuffled list of with fold no in a tuple(so that points can be identified)\n",
    "'''\n",
    "def k_fold_splitter(obs_no,k=10):\n",
    "    \n",
    "    # suffle points\n",
    "    np.random.seed(1)\n",
    "    points=list(range(obs_no))\n",
    "    np.random.shuffle(points)\n",
    "\n",
    "    factor=obs_no//k\n",
    "\n",
    "    # init split folds store list\n",
    "    k_fold_list=list()\n",
    "\n",
    "    # k-1 folds are of equal size\n",
    "    # fold count starts from 0 and goes upto (k-1)\n",
    "    for i in range(k-1):\n",
    "        for j in range(factor):\n",
    "            k_fold_list.append((points[j],i))\n",
    "    \n",
    "    counted_no=len(k_fold_list)\n",
    "\n",
    "    # last fold holds everything that is remaining\n",
    "    for i in range(obs_no-len(k_fold_list)):\n",
    "        k_fold_list.append((points[i+counted_no],k-1))\n",
    "\n",
    "    return k_fold_list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### cross-validation(k-fold) steps followed:\n",
    "\n",
    "- first split data into k-folds using the function defined above\n",
    "- repeat these two steps until each of the k-folds has served as the test set\n",
    "    - pick one as test and others as train folds and \n",
    "    - report testing f1 score for that run\n",
    "- the average of your k recorded scores is called the cross-validation score and will serve as your performance metric for the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "simple function to cross validate\n",
    "steps explined in above cell\n",
    "'''\n",
    "def cross_valid(folds,margin=0,learn_rate=1,n_iter=100):\n",
    "\n",
    "    np.random.seed(1)\n",
    "    global data\n",
    "\n",
    "    split_tuple_list=k_fold_splitter(data.shape[0],k=folds)\n",
    "\n",
    "    f1_list=list()\n",
    "    weight_list=list()\n",
    "\n",
    "    for i in range(folds):\n",
    "\n",
    "        fold_point_list=[]\n",
    "        test_point_list=[]\n",
    "\n",
    "        for point in split_tuple_list:\n",
    "            if point[1]!=i:\n",
    "                fold_point_list.append(point[0])\n",
    "            else:\n",
    "                test_point_list.append(point[0])\n",
    "\n",
    "        # training data\n",
    "        train_fold_data=data.iloc[fold_point_list,:]\n",
    "        train_y=list(train_fold_data['class'])\n",
    "        train_x=np.array(train_fold_data.drop('class',axis=1))\n",
    "\n",
    "        # testing data\n",
    "        test_fold_data=data.iloc[test_point_list,:]\n",
    "        test_y=list(test_fold_data['class'])\n",
    "        test_x=np.array(test_fold_data.drop('class',axis=1))\n",
    "\n",
    "        # train\n",
    "        w=percep(train_x,train_y,margin,learn_rate,n_iter) # with default values\n",
    "        weight_list.append(w)\n",
    "        \n",
    "        # predict on test fold points\n",
    "        y_pred=[predict(new_point,w) for new_point in test_x]\n",
    "\n",
    "        # calc f1-score using the function\n",
    "        f1=f1_score(test_y,y_pred)\n",
    "\n",
    "        # store f1-score of the test ith fold\n",
    "        f1_list.append(f1)\n",
    "\n",
    "        # print(f'Testing F1 score for test fold {str(i+1)} is {f1}')\n",
    "\n",
    "    return {'f1-scores':f1_list,'weights':weight_list}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "avg F1 score(cross-validation score) is 0.879\n"
     ]
    }
   ],
   "source": [
    "folds=10\n",
    "# using default values\n",
    "cross_data=cross_valid(folds)\n",
    "print(f'avg F1 score(cross-validation score) is {round(sum(cross_data[\"f1-scores\"])/folds,3)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part(d)\n",
    "\n",
    "#### Ensure you use a held out validation set and report F1 score on the held out set for your best model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### best model strategy implemented\n",
    "\n",
    "- there are mainly 3 hyperparameters in perceptron algo\n",
    "- by changing them one by one we decide which one is best others are held constant [we also could do grid search but takes much more time]\n",
    "- then on best model parameters we give avg cross-validated test set F1 score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# of iterations=100 || avg F1 score is 0.879\n",
      "# of iterations=1000 || avg F1 score is 0.89\n",
      "# of iterations=10000 || avg F1 score is 0.912\n"
     ]
    }
   ],
   "source": [
    "# model avg f1-score for diff # of iters\n",
    "for n in [100,1000,10000]:\n",
    "    cross_data=cross_valid(folds,n_iter=n)\n",
    "    print(f'# of iterations={n} || avg F1 score is {round(sum(cross_data[\"f1-scores\"])/folds,3)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- there is slight improvment but not quite significant\n",
    "    - 10000 gives best out of these"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "learn rate=0.0 || avg F1 score is 0.19\n",
      "learn rate=0.11 || avg F1 score is 0.853\n",
      "learn rate=0.22 || avg F1 score is 0.867\n",
      "learn rate=0.33 || avg F1 score is 0.891\n",
      "learn rate=0.44 || avg F1 score is 0.884\n",
      "learn rate=0.56 || avg F1 score is 0.861\n",
      "learn rate=0.67 || avg F1 score is 0.889\n",
      "learn rate=0.78 || avg F1 score is 0.823\n",
      "learn rate=0.89 || avg F1 score is 0.91\n",
      "learn rate=1.0 || avg F1 score is 0.879\n"
     ]
    }
   ],
   "source": [
    "# model avg f1-score for diff learning rates\n",
    "for m in list(np.linspace(0,1,10)):\n",
    "    cross_data=cross_valid(folds,learn_rate=m)\n",
    "    print(f'learn rate={round(m,2)} || avg F1 score is {round(sum(cross_data[\"f1-scores\"])/folds,3)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- there is slight up-downs but no drastic improvements-drops\n",
    "    - 0.89 gives best out of these"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "margin=0.0 || avg F1 score(cross-validation score) is 0.879\n",
      "margin=0.11 || avg F1 score(cross-validation score) is 0.879\n",
      "margin=0.22 || avg F1 score(cross-validation score) is 0.856\n",
      "margin=0.33 || avg F1 score(cross-validation score) is 0.886\n",
      "margin=0.44 || avg F1 score(cross-validation score) is 0.874\n",
      "margin=0.56 || avg F1 score(cross-validation score) is 0.899\n",
      "margin=0.67 || avg F1 score(cross-validation score) is 0.891\n",
      "margin=0.78 || avg F1 score(cross-validation score) is 0.899\n",
      "margin=0.89 || avg F1 score(cross-validation score) is 0.898\n",
      "margin=1.0 || avg F1 score(cross-validation score) is 0.89\n"
     ]
    }
   ],
   "source": [
    "# model avg f1-score for diff margins\n",
    "for m in list(np.linspace(0,1,10)):\n",
    "    cross_data=cross_valid(folds,margin=m)\n",
    "    print(f'margin={round(m,2)} || avg F1 score(cross-validation score) is {round(sum(cross_data[\"f1-scores\"])/folds,3)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- no significant changes\n",
    "    - we choose 0 that was the default"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "for best model avg F1 score on held-out data is 0.906\n"
     ]
    }
   ],
   "source": [
    "best_margin=0\n",
    "best_rate=0.89\n",
    "best_n_iters=10000\n",
    "\n",
    "cross_data=cross_valid(folds,margin=best_margin,learn_rate=best_rate,n_iter=best_n_iters)\n",
    "print(f'for best model avg F1 score on held-out data is {round(sum(cross_data[\"f1-scores\"])/folds,3)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Q2\n",
    "\n",
    "#### Let’s consider a simple demonstration of MCMC sampling in a setting where conjugacy is actually possible – normal likelihoods with a known population variance, for which the prior is another normal distribution"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part(a)\n",
    "\n",
    "#### Write a function to calculate the Bayesian posterior probability given 50 new data samples drawn from a normal distribution with mean 10 and SD 5, assuming a normal prior with mean 25 and s.d. 5. Plot the pdfs of the prior, the likelihood and the posterior distributions. Explain how you derive the likelihood from the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "this takes likelihood and prior parameters as input\n",
    "and returns posterior mean and sd using the formulas \n",
    "their derivation is explained in markdown comments\n",
    "'''\n",
    "def posterior(n_samples=50,lik_mean=10,lik_sd=5,prior_mean=25,prior_sd=5):\n",
    "    # to reproduce random state is fixed\n",
    "    np.random.seed(1)\n",
    "    samples=np.random.normal(lik_mean,lik_sd,n_samples)\n",
    "   \n",
    "    # formulas derivations for these calc explained in markdowns\n",
    "\n",
    "    post_sd=np.sqrt((lik_sd**2*prior_sd**2)/(lik_sd**2+prior_sd**2))\n",
    "\n",
    "    post_mean=((lik_sd**2)*(prior_mean)+(n_samples*prior_sd**2)*(np.mean(samples)))/((n_samples*prior_sd**2)+lik_sd**2)\n",
    "\n",
    "    return {'post_mean':round(post_mean,2),'post_sd':round(post_sd,3)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "takes mean and sd of an normal dist\n",
    "and returns \n",
    "    - a equi space points around mean with 3*sd width and \n",
    "    - its pdf value for given normal dist in a dictionary \n",
    "'''\n",
    "def norm_data(mean,sd):\n",
    "    x=np.linspace(-3*sd+mean,mean+3*sd,100)\n",
    "    norm_pdf = (1/(np.sqrt(2*np.pi) * sd )) * np.exp(-0.5*((x-mean)/sd)**2)\n",
    "    return {'x':list(x),'pdf':list(norm_pdf)}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### To plot lik-prior-posterior data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "# init given info\n",
    "n_samples=200\n",
    "lik_mean=10\n",
    "lik_sd=5\n",
    "prior_mean=25\n",
    "prior_sd=5\n",
    "\n",
    "# call posterior function to get params values with default values\n",
    "post=posterior()\n",
    "\n",
    "# get x-y data for plots\n",
    "lik_data=norm_data(lik_mean,lik_sd)\n",
    "prior_data=norm_data(prior_mean,prior_sd)\n",
    "post_data=norm_data(post['post_mean'],post['post_sd'])\n",
    "\n",
    "# plot pdf compare graph\n",
    "plt.plot(lik_data['x'],lik_data['pdf'],label='lik',color='black')\n",
    "plt.plot(prior_data['x'],prior_data['pdf'],label='prior',color='red')\n",
    "plt.plot(post_data['x'],post_data['pdf'],label='posterior',color='green')\n",
    "plt.legend()\n",
    "plt.title(\"Density plot for lik, prior, and posterior\")\n",
    "plt.ylabel('pdf-values')\n",
    "plt.xlabel('x')\n",
    "plt.savefig('q2-a.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### observations:\n",
    "- for these specific values\n",
    "    - posterior mean has shifted in the direction of prior only by a very small amount(0.17) and \n",
    "    - sd has dropped to 3.536 from 5 that was for likelihood and prior."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `Explain Likelihood Derivation from Data`\n",
    "\n",
    "We basically have to derive the likehood from the samples we generated in `posterior` function. We will consider a general situation with mean $\\mu$ and sd $\\sigma$. Our data is just a specific case of that.\n",
    "\n",
    "Now, consider N i.i.d. scalar obs $X = \\{x_1 , x_2 , \\ldots , x_N \\}$ drawn from a normal distribution with mean $\\mu$ and sd $\\sigma$. So, $\\forall x \\in \\{1,\\ldots,N\\}$ we have :\n",
    "$$\n",
    "p(x_n|\\mu,\\sigma^2)=\\mathcal{N}(x_n|\\mu,\\sigma^2)\n",
    "$$\n",
    "\n",
    "Or we can write,\n",
    "$$\n",
    "p(x_n|\\mu,\\sigma^2)  = \\frac{1}{\\sqrt{2\\pi \\sigma^2}}exp\\left[-\\frac{(x_n-\\mu)^2}{2\\sigma^2}\\right]\n",
    "$$\n",
    "\n",
    "Using above we can give joint likelihood simply as their product(as they are iid),\n",
    "$$\n",
    "p(X|\\mu,\\sigma^2)  = \\prod_{n=1}^N p(x_n|\\mu,\\sigma^2)\n",
    "$$\n",
    "\n",
    "Full expanded version can be given as,\n",
    "$$\n",
    "p(X|\\mu,\\sigma^2)  = \\frac{1}{(2\\pi)^{n/2} \\sigma^n}exp\\left[-\\frac{1}{2\\sigma^2} \\sum_{n=1}^N (x_n-\\mu)^2\\right]\n",
    "$$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `posterior derivation formulas explained`\n",
    "\n",
    "To get posterior for `mean`($\\mu$) from lik and prior we can use bayes formula,\n",
    "$$\n",
    "p(\\mu|X)=\\frac{p(X|\\mu)p(\\mu)}{p(X)}=\\frac{p(X|\\mu)p(\\mu)}{\\int p(X|\\mu)p(\\mu)}\n",
    "$$\n",
    "\n",
    "Up to proportinality we write(as integral is just a constant ),\n",
    "$$\n",
    "p(\\mu|X) \\propto p(X|\\mu)p(\\mu)\n",
    "$$\n",
    "\n",
    "**`Lik:`**\n",
    "\n",
    "Given in above section. We will ignore constants(w.r.t. to $\\mu$) though.\n",
    "\n",
    "**`Prior:`**\n",
    "\n",
    "For general case when prior for $\\mu$ is a Guassian with mean $\\mu_0$ and sd $\\sigma_0$, we can write prior distribution,\n",
    "$$\n",
    "p(\\mu|\\mu_0,\\sigma_0^2)  = \\frac{1}{\\sqrt{2\\pi \\sigma_0^2}}exp\\left[-\\frac{(\\mu-\\mu_0)^2}{2\\sigma_0^2}\\right]\n",
    "$$\n",
    "\n",
    "**`Posterior:`**\n",
    "\n",
    "Use Baues rule upto constant,\n",
    "$$\n",
    "p(\\mu|X) \\propto \\left(\n",
    "    \\frac{1}{(2\\pi)^{n/2} \\sigma^n}exp\\left[-\\frac{1}{2\\sigma^2} \\sum_{n=1}^N (x_n-\\mu)^2\\right]\\right) \\left(\\frac{1}{\\sqrt{2\\pi \\sigma_0^2}}exp\\left[-\\frac{(\\mu-\\mu_0)^2}{2\\sigma_0^2}\\right]\\right)\n",
    "$$\n",
    "\n",
    "WE also can ignore other constants like $\\sigma$(as it si known) and $\\sigma_0$,\n",
    "$$\n",
    "p(\\mu|X) \\propto \\left(\n",
    "    exp\\left[-\\frac{1}{2\\sigma^2} \\sum_{n=1}^N (x_n-\\mu)^2\\right]\\right) \\left(exp\\left[-\\frac{(\\mu-\\mu_0)^2}{2\\sigma_0^2}\\right]\\right)\n",
    "$$\n",
    "\n",
    "After using square trick and comaring with\n",
    "$$\n",
    "p(\\mu|X)  \\propto exp\\left[-\\frac{(\\mu-\\mu_N)^2}{2\\sigma_N^2}\\right]\n",
    "$$\n",
    "\n",
    "we get Gaussian posterior’s precision as the sum of the prior’s precision and sum of the noise\n",
    "precisions of all the observations,\n",
    "$$\n",
    "\\frac{1}{\\sigma_N^2}=\\frac{1}{\\sigma_0^z} + \\frac{N}{\\sigma^2}\n",
    "$$\n",
    "\n",
    "and Gaussian posterior’s mean is a convex combination of prior’s mean and the MLE solution,\n",
    "$$\n",
    "\\mu_N=\\frac{\\mu_0 \\sigma^2+\\bar{x}N\\sigma_0^2}{N\\sigma_0^2+\\sigma^2}\n",
    "$$\n",
    "\n",
    "Here: $\\bar{x}=\\frac{\\sum_{n=1}^N x_n}{N}$\n",
    "\n",
    "NOTE: these formulas have been used in `posterior()` function to get posterior mean and SD parameter values\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part(b)\n",
    "\n",
    "#### Implement the Metropolis algorithm from the lecture slides to estimate the posterior distribution given the same prior and data and show that it converges to the analytic posterior by plotting a histogram of samples from the distribution alongside the analytic posterior distribution.  Assume whatever SD (width) you want for the proposal distribution."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `Metropolish Hastings Algorithm`\n",
    "\n",
    "Now suppose that we did not know about square trick then it won't have been easy to do this integral and compute above posterior in closed and nice form. And that happens all the time in real worl dproblem. So, we are going to experiment with this problem where we suppose we don't know how to solve above problem and we will use Monte Carlo Markov Chains to get enough samples from the posterior distribution formula up to prop constant and we call this our `Target` distribution from which we need samples but we can not as it is not a standard known dist. That is why we use a proposal dist(TBD) that conditions on the immediately previous $\\mu$ value (say a Gaussian).\n",
    "\n",
    "Here we have to decide what to use as our proposal(jump) distribution. Since we know our posterior(target dist) has support all over the real line, we can consider Univariate Norrmal Distribution for this case as it does cover real line and also simple sample from. \n",
    "\n",
    "So our proposal distribution is a Normal Distribution. \n",
    "\n",
    "**`Algo Steps:`** A general MH algo steps are,\n",
    "\n",
    "Let $x_0 =init$ and for a $k^{th}$ step when $x_k=x$ and to obtain $x_{k+1}$ we do these steps:\n",
    "1. Sample a new possible proposal $y$ from the jump distribution that conditions on the immediately previous (that is $x$ here) value.\n",
    "2. Calculate the ratio of the proposed posterior distribution to the current one. The ratios is given by\n",
    "$$\n",
    "r=\\frac{f(y)g(x|y)}{f(x)g(y|x)}\n",
    "$$\n",
    "\n",
    "But since we are using guassian dist as our proposal we have $g(x|y)=g(y|x)$. meaning it is symmatric. We have same probability of going from x to y as y to x. So, remember here f is our posterior distribution upto prop constant,\n",
    "$$\n",
    "r=\\frac{f(y)}{f(x)}\n",
    "$$\n",
    "\n",
    "3. Sample a random number a between 0 and 1 using `Uniform dist` --> $U(0,1)$. Say the sample is `a`\n",
    "4. If r > a, accept the proposed $y$, otherwise stick with the earlier $y$\n",
    "5. This gives one sample from the target distribution. We can repeat above steps to get more samples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "function to compute target dist's probability value in each run\n",
    "takes a point from support space(real line here)\n",
    "returns log of the posterior dist at that point\n",
    "we have used log for computational stability(it does not affect inequality condition for choosing samples from MCMC as it is monotionic)\n",
    "'''\n",
    "def log_post(x,mean,sd):\n",
    "    # log og posterior up to prop constant\n",
    "    log_p=-((x-mean)/sd)**2\n",
    "    \n",
    "    return log_p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "acceptance rate is 50.3 with jump SD=5\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "takes hyperparameter values and\n",
    "returns mcmc samples\n",
    "other things explained in func comments\n",
    "'''\n",
    "no_of_samples=10000\n",
    "def mh(jump_sd=5,init=10,no_of_samples=1000):\n",
    "    global post\n",
    "    # to reproduce results\n",
    "    np.random.seed(1)\n",
    "\n",
    "    # list to store samples\n",
    "    mcmc_samples=list()\n",
    "\n",
    "    x_curr=init\n",
    "    '''\n",
    "    x_curr=10 # inital value --> hyper-para\n",
    "    no_of_samples=10000 # hyper-para\n",
    "    jump_sd=5 # hyper-para\n",
    "    '''\n",
    "\n",
    "    acc_count=0\n",
    "    for i in range(no_of_samples):\n",
    "        # propose a new value from jump dist\n",
    "        y_prop=np.random.normal(x_curr,jump_sd)\n",
    "\n",
    "        # calc ratio( in log ) --> posterior parameters\n",
    "        r=(log_post(y_prop,post['post_mean'],post['post_sd']))-(log_post(x_curr,post['post_mean'],post['post_sd']))\n",
    "\n",
    "        # propose random sample from uniform\n",
    "        u=np.random.uniform(0,1)\n",
    "\n",
    "        # accept-reject condition for MH\n",
    "        if r > np.log(u):\n",
    "            mcmc_samples.append(y_prop)\n",
    "            # update value of current sample\n",
    "            x_curr=y_prop\n",
    "            # update acceptance count\n",
    "            acc_count+=1\n",
    "        else:\n",
    "            mcmc_samples.append(x_curr)\n",
    "    \n",
    "    print(f'acceptance rate is {acc_count*100/no_of_samples} with jump SD={jump_sd}')\n",
    "    return mcmc_samples\n",
    "\n",
    "\n",
    "# actual posterior params that we got in first que is used\n",
    "actual_samples=np.random.normal(post['post_mean'],post['post_sd'],no_of_samples)\n",
    "# func return\n",
    "mcmc_samples=mh(no_of_samples=no_of_samples)\n",
    "# plot hists to compare\n",
    "plt.hist(mcmc_samples,label='estimate(MCMC)',bins=100,alpha=0.3,density=True)\n",
    "plt.hist(actual_samples,label='analytic',bins=100,alpha=0.3,density=True)\n",
    "plt.legend()\n",
    "plt.title(\"hist plot for mcmc and posterior(actual) samples\")\n",
    "plt.xlabel('x')\n",
    "plt.savefig('q2-b.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part(c)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### How does the speed of convergence of the sampling depend on the proposal width? Is there an optimal proposal width that would work best? Demonstrate the consequences of using sub-optimal proposal width and terminating sampling too soon."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- we can measure spped of convergance by acceptance rate; when for fixed no of iterations and different jump SDs acceptance rate is low we know that algo will take more time to converge and vice-versa."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "acceptance rate is 86.74 with jump SD=1\n",
      "acceptance rate is 75.76 with jump SD=2\n",
      "acceptance rate is 65.44 with jump SD=3\n",
      "acceptance rate is 50.3 with jump SD=5\n",
      "acceptance rate is 39.48 with jump SD=7\n",
      "acceptance rate is 29.4 with jump SD=10\n"
     ]
    }
   ],
   "source": [
    "# with 10000 iterations being fixed\n",
    "for sd in [1,2,3,5,7,10]:\n",
    "    mcmc_samples=mh(jump_sd=sd,no_of_samples=no_of_samples)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### obervatios on convergance speed\n",
    "\n",
    "- If SD is high, then we would have more rejections and thus we would have covered less unique points in the support space, that means we would need more iterations to cover the support space; that implies that we would need more time.\n",
    "- When SD is low reverse thing happens, we are moving quite quckely as acceptance rate is high and we cover space quickely and in less no of iterations.\n",
    "\n",
    "`so speed of convergance depends inversely on the proposal width`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Observations on optimal width for proposal\n",
    "\n",
    "From the above example it is clear that the quality of the MCMC sampler is determined by the choice of the variance in the proposal distribution(SD).\n",
    "- If SD is too large, then we will propose values potentially too far away, which in principle would be good, but this means a lot of the values will be rejected. That means we will stay where we are quite often, increasing the correlation(samples would be highly corr with their previous values as most of the time we would not even move) in the samples\n",
    "- If SD is too small, then we will make tiny moves implying we may accept a lot of them, but the samples obtained will be quite dependent.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### bad mcmc\n",
    "\n",
    "- very less no of iterations are given to the model\n",
    "- also either very high or very low SD is given to the model\n",
    "\n",
    "- these situations can lead to very bad samples when given inital value far off from mean of actual posterior"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- with high SD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "acceptance rate is 2.1 with jump SD=200\n"
     ]
    }
   ],
   "source": [
    "no_of_samples=1000\n",
    "# actual posterior params that we got in first que is used\n",
    "actual_samples=np.random.normal(post['post_mean'],post['post_sd'],no_of_samples)\n",
    "# func return\n",
    "mcmc_samples=mh(jump_sd=200,init=-10,no_of_samples=no_of_samples)\n",
    "# plot hists to compare\n",
    "plt.hist(mcmc_samples,label='estimate(MCMC)',bins=100,alpha=0.3,density=True)\n",
    "plt.hist(actual_samples,label='analytic',bins=100,alpha=0.3,density=True)\n",
    "plt.legend()\n",
    "plt.title(\"hist plot for mcmc and posterior(actual) samples\")\n",
    "plt.xlabel('x')\n",
    "plt.savefig('q2-c1.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- with very low SD(although acceptance rate is high but of no use as we are not exploring in right place when initalization is very bad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "acceptance rate is 99.3 with jump SD=0.01\n"
     ]
    }
   ],
   "source": [
    "no_of_samples=1000\n",
    "# actual posterior params that we got in first que is used\n",
    "actual_samples=np.random.normal(post['post_mean'],post['post_sd'],no_of_samples)\n",
    "# func return\n",
    "mcmc_samples=mh(jump_sd=0.01,init=0,no_of_samples=no_of_samples)\n",
    "# plot hists to compare\n",
    "plt.hist(mcmc_samples,label='estimate(MCMC)',bins=100,alpha=0.3,density=True)\n",
    "plt.hist(actual_samples,label='analytic',bins=100,alpha=0.3,density=True)\n",
    "plt.legend()\n",
    "plt.title(\"hist plot for mcmc and posterior(actual) samples\")\n",
    "plt.xlabel('x')\n",
    "plt.savefig('q2-c2.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- with nice values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "acceptance rate is 50.9 with jump SD=5\n"
     ]
    }
   ],
   "source": [
    "no_of_samples=1000\n",
    "# actual posterior params that we got in first que is used\n",
    "actual_samples=np.random.normal(post['post_mean'],post['post_sd'],no_of_samples)\n",
    "# func return\n",
    "mcmc_samples=mh(jump_sd=5,init=10,no_of_samples=no_of_samples)\n",
    "# plot hists to compare\n",
    "plt.hist(mcmc_samples,label='estimate(MCMC)',bins=100,alpha=0.3,density=True)\n",
    "plt.hist(actual_samples,label='analytic',bins=100,alpha=0.3,density=True)\n",
    "plt.legend()\n",
    "plt.title(\"hist plot for mcmc and posterior(actual) samples\")\n",
    "plt.xlabel('x')\n",
    "plt.savefig('q2-c3.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- although acceptance rate is not that good but also not that bad\n",
    "- even with 1000 iterations gives nice enough picture about actual posterior\n",
    "- other cases also can be considered when parameter values are not that good"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "365d70965140afb04a698773bfdd31483bc82432b779112c2a78b5de7c16d125"
  },
  "kernelspec": {
   "display_name": "Python 3.8.5 64-bit ('base': conda)",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
